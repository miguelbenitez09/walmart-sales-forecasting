{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9f3406",
   "metadata": {},
   "source": [
    "## üì¶ 1. Importar Librer√≠as\n",
    "\n",
    "sklearn, XGBoost, LightGBM para modelado de regresi√≥n y evaluaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import pickle\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Crear directorio de reportes\n",
    "os.makedirs('../E_reports', exist_ok=True)\n",
    "os.makedirs('../reports/figures', exist_ok=True)\n",
    "\n",
    "print('‚úÖ Librer√≠as cargadas')\n",
    "print('üìÅ Directorios de reportes creados')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b136f6",
   "metadata": {},
   "source": [
    "## üìÇ 2. Cargar Datos Procesados\n",
    "\n",
    "Carga de X_train, X_val, y_train, y_val desde data/02_processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_PATH = '../data/02_processed/'\n",
    "MODELS_PATH = '../models/'\n",
    "\n",
    "X_train = pd.read_csv(PROCESSED_PATH + 'X_train.csv')\n",
    "X_val = pd.read_csv(PROCESSED_PATH + 'X_val.csv')\n",
    "y_train = pd.read_csv(PROCESSED_PATH + 'y_train.csv')['Weekly_Sales']\n",
    "y_val = pd.read_csv(PROCESSED_PATH + 'y_val.csv')['Weekly_Sales']\n",
    "\n",
    "train_full = pd.read_csv(PROCESSED_PATH + 'train_processed.csv')\n",
    "val_full = pd.read_csv(PROCESSED_PATH + 'val_processed.csv')\n",
    "\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'X_val: {X_val.shape}, y_val: {y_val.shape}')\n",
    "print(f'Features: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d33e18",
   "metadata": {},
   "source": [
    "## üéØ 3. Implementar M√©trica WMAE\n",
    "\n",
    "M√©trica de evaluaci√≥n: festivos pesan 5x, d√≠as normales 1x (seg√∫n competencia Kaggle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2380bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmae(y_true, y_pred, is_holiday):\n",
    "    \"\"\"\n",
    "    Weighted Mean Absolute Error (WMAE).\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: valores reales\n",
    "    - y_pred: predicciones\n",
    "    - is_holiday: array booleano indicando festivos\n",
    "    \n",
    "    Returns:\n",
    "    - wmae_score: m√©trica WMAE\n",
    "    \"\"\"\n",
    "    weights = np.where(is_holiday, 5, 1)\n",
    "    mae_weighted = np.abs(y_true - y_pred) * weights\n",
    "    return np.sum(mae_weighted) / np.sum(weights)\n",
    "\n",
    "print('‚úÖ Funci√≥n WMAE implementada')\n",
    "print('\\nF√≥rmula: WMAE = Œ£(w_i * |y_i - ≈∑_i|) / Œ£(w_i)')\n",
    "print('donde w_i = 5 si festivo, 1 si normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181ac8e",
   "metadata": {},
   "source": [
    "## üìä 4. Modelo Baseline\n",
    "\n",
    "Media hist√≥rica por Store-Dept como modelo de referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_means = train_full.groupby(['Store','Dept'])['Weekly_Sales'].mean().to_dict()\n",
    "\n",
    "def baseline_predict(df):\n",
    "    predictions = []\n",
    "    for _, row in df.iterrows():\n",
    "        key = (row['Store'], row['Dept'])\n",
    "        predictions.append(baseline_means.get(key, train_full['Weekly_Sales'].mean()))\n",
    "    return np.array(predictions)\n",
    "\n",
    "y_pred_baseline = baseline_predict(val_full)\n",
    "is_holiday_val = val_full['IsHoliday'].values\n",
    "\n",
    "baseline_wmae = wmae(y_val, y_pred_baseline, is_holiday_val)\n",
    "baseline_mae = mean_absolute_error(y_val, y_pred_baseline)\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_val, y_pred_baseline))\n",
    "baseline_r2 = r2_score(y_val, y_pred_baseline)\n",
    "\n",
    "print('='*70)\n",
    "print('üìä BASELINE MODEL (Media Hist√≥rica)')\n",
    "print('='*70)\n",
    "print(f'WMAE: ${baseline_wmae:,.2f}')\n",
    "print(f'MAE: ${baseline_mae:,.2f}')\n",
    "print(f'RMSE: ${baseline_rmse:,.2f}')\n",
    "print(f'R¬≤: {baseline_r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d287728d",
   "metadata": {},
   "source": [
    "## üå≥ 5. Random Forest\n",
    "\n",
    "100 √°rboles, max_depth=20, n_jobs=-1 para paralelizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b13274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üå≥ Entrenando Random Forest...\\n')\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "rf_wmae = wmae(y_val, y_pred_rf, is_holiday_val)\n",
    "rf_mae = mean_absolute_error(y_val, y_pred_rf)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_val, y_pred_rf))\n",
    "rf_r2 = r2_score(y_val, y_pred_rf)\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('üå≥ RANDOM FOREST')\n",
    "print('='*70)\n",
    "print(f'WMAE: ${rf_wmae:,.2f} | Mejora: {(baseline_wmae-rf_wmae)/baseline_wmae*100:.2f}%')\n",
    "print(f'MAE: ${rf_mae:,.2f}')\n",
    "print(f'RMSE: ${rf_rmse:,.2f}')\n",
    "print(f'R¬≤: {rf_r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786951f5",
   "metadata": {},
   "source": [
    "## ‚ö° 6. XGBoost\n",
    "\n",
    "200 estimadores, learning_rate=0.05, early_stopping para prevenir overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd8b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rf = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print('\\nüìä Top 20 Features m√°s importantes (Random Forest):\\n')\n",
    "print(feature_importance_rf.head(20))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance_rf.head(20)\n",
    "plt.barh(range(len(top_features)), top_features['Importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importance - Random Forest')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fedea8",
   "metadata": {},
   "source": [
    "## üí° 7. LightGBM\n",
    "\n",
    "200 estimadores, learning_rate=0.05, optimizado para datasets grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('‚ö° Entrenando XGBoost...\\n')\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_val)\n",
    "\n",
    "xgb_wmae = wmae(y_val, y_pred_xgb, is_holiday_val)\n",
    "xgb_mae = mean_absolute_error(y_val, y_pred_xgb)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_val, y_pred_xgb))\n",
    "xgb_r2 = r2_score(y_val, y_pred_xgb)\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('‚ö° XGBOOST')\n",
    "print('='*70)\n",
    "print(f'WMAE: ${xgb_wmae:,.2f} | Mejora: {(baseline_wmae-xgb_wmae)/baseline_wmae*100:.2f}%')\n",
    "print(f'MAE: ${xgb_mae:,.2f}')\n",
    "print(f'RMSE: ${xgb_rmse:,.2f}')\n",
    "print(f'R¬≤: {xgb_r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8599e7",
   "metadata": {},
   "source": [
    "## üìä 8. Comparaci√≥n de Modelos\n",
    "\n",
    "Tabla comparativa de WMAE, MAE, RMSE, R¬≤ y tiempo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28339d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üöÄ Entrenando LightGBM...\\n')\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='mae',\n",
    "    callbacks=[lgb.early_stopping(20), lgb.log_evaluation(10)]\n",
    ")\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(X_val)\n",
    "\n",
    "lgb_wmae = wmae(y_val, y_pred_lgb, is_holiday_val)\n",
    "lgb_mae = mean_absolute_error(y_val, y_pred_lgb)\n",
    "lgb_rmse = np.sqrt(mean_squared_error(y_val, y_pred_lgb))\n",
    "lgb_r2 = r2_score(y_val, y_pred_lgb)\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('üöÄ LIGHTGBM')\n",
    "print('='*70)\n",
    "print(f'WMAE: ${lgb_wmae:,.2f} | Mejora: {(baseline_wmae-lgb_wmae)/baseline_wmae*100:.2f}%')\n",
    "print(f'MAE: ${lgb_mae:,.2f}')\n",
    "print(f'RMSE: ${lgb_rmse:,.2f}')\n",
    "print(f'R¬≤: {lgb_r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelos adicionales para comparaci√≥n completa\n",
    "print('\\nüöÄ Entrenando modelos adicionales...\\n')\n",
    "\n",
    "additional_models = {\n",
    "    'CatBoost': CatBoostRegressor(n_estimators=200, max_depth=8, learning_rate=0.1, \n",
    "                                  random_state=42, verbose=0),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=8, \n",
    "                                                   learning_rate=0.1, random_state=42),\n",
    "    'Extra Trees': ExtraTreesRegressor(n_estimators=100, max_depth=20, \n",
    "                                      random_state=42, n_jobs=-1),\n",
    "    'Ridge': Ridge(alpha=1.0, random_state=42),\n",
    "    'Lasso': Lasso(alpha=1.0, random_state=42, max_iter=2000),\n",
    "    'ElasticNet': ElasticNet(alpha=1.0, random_state=42, max_iter=2000)\n",
    "}\n",
    "\n",
    "additional_results = {}\n",
    "\n",
    "for name, model in additional_models.items():\n",
    "    print(f'  üîπ Entrenando {name}...')\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    elapsed_time = (datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    additional_results[name] = {\n",
    "        'predictions': y_pred,\n",
    "        'wmae': wmae(y_val, y_pred, is_holiday_val),\n",
    "        'mae': mean_absolute_error(y_val, y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_val, y_pred)),\n",
    "        'r2': r2_score(y_val, y_pred),\n",
    "        'time': elapsed_time,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    print(f'     WMAE: ${additional_results[name][\"wmae\"]:,.2f} | Time: {elapsed_time:.2f}s')\n",
    "\n",
    "print('\\n‚úÖ Todos los modelos entrenados')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295e3a4",
   "metadata": {},
   "source": [
    "## üèÜ 9. Seleccionar Mejor Modelo\n",
    "\n",
    "Selecci√≥n del modelo con menor WMAE (m√©trica de competencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbce8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame completo de resultados\n",
    "all_results = [\n",
    "    {'Model': 'Baseline', 'WMAE': baseline_wmae, 'MAE': baseline_mae, \n",
    "     'RMSE': baseline_rmse, 'R¬≤': baseline_r2, 'Time': 0},\n",
    "    {'Model': 'Random Forest', 'WMAE': rf_wmae, 'MAE': rf_mae, \n",
    "     'RMSE': rf_rmse, 'R¬≤': rf_r2, 'Time': 0},\n",
    "    {'Model': 'XGBoost', 'WMAE': xgb_wmae, 'MAE': xgb_mae, \n",
    "     'RMSE': xgb_rmse, 'R¬≤': xgb_r2, 'Time': 0},\n",
    "    {'Model': 'LightGBM', 'WMAE': lgb_wmae, 'MAE': lgb_mae, \n",
    "     'RMSE': lgb_rmse, 'R¬≤': lgb_r2, 'Time': 0}\n",
    "]\n",
    "\n",
    "for name, res in additional_results.items():\n",
    "    all_results.append({\n",
    "        'Model': name,\n",
    "        'WMAE': res['wmae'],\n",
    "        'MAE': res['mae'],\n",
    "        'RMSE': res['rmse'],\n",
    "        'R¬≤': res['r2'],\n",
    "        'Time': res['time']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(all_results).sort_values('WMAE')\n",
    "\n",
    "# Guardar resultados en CSV\n",
    "results_df.to_csv('../reports/model_comparison_results.csv', index=False)\n",
    "print('‚úÖ Resultados guardados: reports/model_comparison_results.csv')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('üìä COMPARACI√ìN DE TODOS LOS MODELOS (10 MODELOS)')\n",
    "print('='*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_wmae = results_df.iloc[0]['WMAE']\n",
    "print(f'\\nüèÜ MEJOR MODELO: {best_model_name}')\n",
    "print(f'   WMAE: ${best_wmae:,.2f}')\n",
    "print(f'   Mejora vs Baseline: {(baseline_wmae-best_wmae)/baseline_wmae*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81e4b7",
   "metadata": {},
   "source": [
    "## üìà 10. Visualizaci√≥n de Resultados\n",
    "\n",
    "Gr√°ficos: real vs predicho, importancia de features, distribuci√≥n de residuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa406700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n completa de comparaci√≥n\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "metrics = ['WMAE', 'MAE', 'RMSE', 'R¬≤', 'Time']\n",
    "titles = ['WMAE (Lower is Better)', 'MAE (Lower is Better)', 'RMSE (Lower is Better)', \n",
    "          'R¬≤ Score (Higher is Better)', 'Training Time (s)']\n",
    "colors = ['#e74c3c', '#f39c12', '#9b59b6', '#2ecc71', '#1abc9c']\n",
    "\n",
    "for idx, (metric, title, color) in enumerate(zip(metrics, titles, colors)):\n",
    "    if idx >= 5:\n",
    "        break\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    \n",
    "    ax = axes[row, col]\n",
    "    data = results_df.sort_values(metric, ascending=(metric != 'R¬≤'))\n",
    "    \n",
    "    bars = ax.barh(data['Model'], data[metric], color=color, edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel('Value', fontsize=11)\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # A√±adir valores\n",
    "    for i, v in enumerate(data[metric]):\n",
    "        if metric in ['WMAE', 'MAE', 'RMSE']:\n",
    "            ax.text(v + max(data[metric])*0.01, i, f'${v:,.0f}', va='center', fontsize=9)\n",
    "        elif metric == 'Time':\n",
    "            ax.text(v + 0.05, i, f'{v:.2f}s', va='center', fontsize=9)\n",
    "        else:\n",
    "            ax.text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=9)\n",
    "\n",
    "# Predicciones vs Reales para el mejor modelo\n",
    "# Determinar mejor modelo\n",
    "if best_model_name in ['Random Forest']:\n",
    "    y_pred_best = y_pred_rf\n",
    "elif best_model_name == 'XGBoost':\n",
    "    y_pred_best = y_pred_xgb\n",
    "elif best_model_name == 'LightGBM':\n",
    "    y_pred_best = y_pred_lgb\n",
    "elif best_model_name in additional_results:\n",
    "    y_pred_best = additional_results[best_model_name]['predictions']\n",
    "else:\n",
    "    y_pred_best = y_pred_baseline\n",
    "\n",
    "ax = axes[1, 2]\n",
    "ax.scatter(y_val, y_pred_best, alpha=0.3, s=10, color='#3498db')\n",
    "ax.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "ax.set_xlabel('Real Sales ($)', fontsize=11)\n",
    "ax.set_ylabel('Predicted Sales ($)', fontsize=11)\n",
    "ax.set_title(f'Real vs Predicted - {best_model_name}', fontsize=13, fontweight='bold')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('üìä An√°lisis Comparativo Completo - 10 Modelos de Regresi√≥n', \n",
    "             y=1.002, fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/01_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print('\\n‚úÖ Figura guardada: reports/figures/01_model_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b25030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de residuos del mejor modelo\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "residuals = y_val - y_pred_best\n",
    "\n",
    "# Histograma de residuos\n",
    "axes[0,0].hist(residuals, bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "axes[0,0].axvline(0, color='red', linestyle='--', lw=2)\n",
    "axes[0,0].set_xlabel('Residuals ($)', fontsize=11)\n",
    "axes[0,0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0,0].set_title('Distribution of Residuals', fontsize=12, fontweight='bold')\n",
    "axes[0,0].grid(alpha=0.3)\n",
    "\n",
    "# Q-Q Plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[0,1])\n",
    "axes[0,1].set_title('Q-Q Plot', fontsize=12, fontweight='bold')\n",
    "axes[0,1].grid(alpha=0.3)\n",
    "\n",
    "# Residuos vs Predicciones\n",
    "axes[1,0].scatter(y_pred_best, residuals, alpha=0.3, s=10, color='purple')\n",
    "axes[1,0].axhline(0, color='red', linestyle='--', lw=2)\n",
    "axes[1,0].set_xlabel('Predicted Sales ($)', fontsize=11)\n",
    "axes[1,0].set_ylabel('Residuals ($)', fontsize=11)\n",
    "axes[1,0].set_title('Residuals vs Predictions', fontsize=12, fontweight='bold')\n",
    "axes[1,0].grid(alpha=0.3)\n",
    "\n",
    "# Residuos absolutos vs Predicciones\n",
    "axes[1,1].scatter(y_pred_best, np.abs(residuals), alpha=0.3, s=10, color='orange')\n",
    "axes[1,1].set_xlabel('Predicted Sales ($)', fontsize=11)\n",
    "axes[1,1].set_ylabel('Absolute Residuals ($)', fontsize=11)\n",
    "axes[1,1].set_title('Absolute Residuals vs Predictions', fontsize=12, fontweight='bold')\n",
    "axes[1,1].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'üìä An√°lisis de Residuos - {best_model_name}', \n",
    "             y=1.001, fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/02_residual_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print('‚úÖ Figura guardada: reports/figures/02_residual_analysis.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20627203",
   "metadata": {},
   "source": [
    "## üíæ 11. Guardar Modelo\n",
    "\n",
    "Exportaci√≥n del mejor modelo a models/ en formato pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "# Seleccionar el mejor modelo\n",
    "if best_model_name == 'LightGBM':\n",
    "    best_model = lgb_model\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_model = xgb_model\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_model = rf_model\n",
    "elif best_model_name in additional_results:\n",
    "    best_model = additional_results[best_model_name]['model']\n",
    "else:\n",
    "    best_model = rf_model  # Default\n",
    "\n",
    "# Guardar modelo\n",
    "model_file = MODELS_PATH + f'best_model_{best_model_name.lower().replace(\" \",\"_\")}.pkl'\n",
    "with open(model_file, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(f'‚úÖ Modelo guardado: {model_file}')\n",
    "\n",
    "# Guardar informaci√≥n del modelo\n",
    "model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'model_type': type(best_model).__name__,\n",
    "    'wmae': best_wmae,\n",
    "    'mae': results_df[results_df['Model']==best_model_name]['MAE'].values[0],\n",
    "    'rmse': results_df[results_df['Model']==best_model_name]['RMSE'].values[0],\n",
    "    'r2': results_df[results_df['Model']==best_model_name]['R¬≤'].values[0],\n",
    "    'feature_names': list(X_train.columns),\n",
    "    'n_features': X_train.shape[1],\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "model_info_file = MODELS_PATH + 'model_info.pkl'\n",
    "with open(model_info_file, 'wb') as f:\n",
    "    pickle.dump(model_info, f)\n",
    "print(f'‚úÖ Informaci√≥n del modelo guardada: {model_info_file}')\n",
    "\n",
    "# Crear reporte de texto completo\n",
    "report_path = '../reports/model_training_report.txt'\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"üìä REPORTE DE ENTRENAMIENTO DE MODELOS\\n\")\n",
    "    f.write(\"Walmart Recruiting - Store Sales Forecasting\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"üìÖ Fecha: {model_info['training_date']}\\n\")\n",
    "    f.write(f\"üë§ Autor: Miguel Antonio Ben√≠tez Gonz√°lez\\n\")\n",
    "    f.write(f\"üìß Email: mbenitezg01@gmail.com\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(f\"ü§ñ MODELOS EVALUADOS: {len(results_df)}\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    for _, row in results_df.iterrows():\n",
    "        f.write(f\"  ‚Ä¢ {row['Model']:<20s} - WMAE: ${row['WMAE']:>10,.2f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    f.write(f\"üèÜ MEJOR MODELO: {best_model_name}\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(f\"WMAE (Weighted MAE):  ${model_info['wmae']:,.2f}\\n\")\n",
    "    f.write(f\"MAE:                  ${model_info['mae']:,.2f}\\n\")\n",
    "    f.write(f\"RMSE:                 ${model_info['rmse']:,.2f}\\n\")\n",
    "    f.write(f\"R¬≤:                   {model_info['r2']:.4f}\\n\")\n",
    "    f.write(f\"\\nMejora vs Baseline:   {(baseline_wmae-best_wmae)/baseline_wmae*100:.2f}%\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    f.write(\"üìà INFORMACI√ìN DE DATOS\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(f\"Tama√±o conjunto entrenamiento: {len(X_train):,} semanas\\n\")\n",
    "    f.write(f\"Tama√±o conjunto validaci√≥n:    {len(X_val):,} semanas\\n\")\n",
    "    f.write(f\"N√∫mero de features:            {model_info['n_features']}\\n\")\n",
    "    f.write(f\"Tiendas:                       45\\n\")\n",
    "    f.write(f\"Departamentos:                 ~81\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    f.write(\"üìÅ ARCHIVOS GENERADOS\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(\"Modelos:\\n\")\n",
    "    f.write(f\"  ‚Ä¢ {model_file}\\n\")\n",
    "    f.write(f\"  ‚Ä¢ {model_info_file}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Reportes:\\n\")\n",
    "    f.write(\"  ‚Ä¢ reports/model_comparison_results.csv\\n\")\n",
    "    f.write(\"  ‚Ä¢ reports/model_training_report.txt\\n\\n\")\n",
    "    \n",
    "    f.write(\"Figuras:\\n\")\n",
    "    f.write(\"  ‚Ä¢ reports/figures/01_model_comparison.png\\n\")\n",
    "    f.write(\"  ‚Ä¢ reports/figures/02_residual_analysis.png\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"‚úÖ ENTRENAMIENTO COMPLETADO CON √âXITO\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(f'‚úÖ Reporte completo guardado: {report_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60fb40b",
   "metadata": {},
   "source": [
    "## üì§ 12. Generar Predicciones para Test\n",
    "\n",
    "Predicciones finales sobre test set para submission (formato Kaggle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa79bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full = pd.read_csv(PROCESSED_PATH + 'test_processed.csv')\n",
    "X_test = test_full.drop(columns=['Date','Type','Type_Holiday','Store_Dept'], errors='ignore')\n",
    "\n",
    "print(f'Test set: {X_test.shape}')\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_full['Store'].astype(str) + '_' + test_full['Dept'].astype(str) + '_' + test_full['Date'].astype(str),\n",
    "    'Weekly_Sales': y_pred_test\n",
    "})\n",
    "\n",
    "submission_file = '../reports/submission.csv'\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f'\\n‚úÖ Predicciones generadas: {len(submission)} filas')\n",
    "print(f'‚úÖ Archivo guardado: {submission_file}')\n",
    "print(f'\\nüìä Estad√≠sticas de predicciones:')\n",
    "print(f'   Media: ${y_pred_test.mean():,.2f}')\n",
    "print(f'   Min: ${y_pred_test.min():,.2f}')\n",
    "print(f'   Max: ${y_pred_test.max():,.2f}')\n",
    "print(f'   Std: ${y_pred_test.std():,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd14490",
   "metadata": {},
   "source": [
    "## ‚úÖ Resumen Final\n",
    "\n",
    "### üéØ Resultados Obtenidos\n",
    "\n",
    "**Mejor Modelo:** {best_model_name}\n",
    "\n",
    "**M√©tricas de Validaci√≥n:**\n",
    "- WMAE: ${best_wmae:,.2f}\n",
    "- Mejora vs Baseline: {(baseline_wmae-best_wmae)/baseline_wmae*100:.2f}%\n",
    "- R¬≤: {results_df.iloc[0]['R¬≤']:.4f}\n",
    "\n",
    "### üì¶ Archivos Generados\n",
    "\n",
    "1. **models/best_model_*.pkl** - Modelo entrenado\n",
    "2. **models/model_metrics.txt** - M√©tricas completas\n",
    "3. **reports/submission.csv** - Predicciones para Kaggle\n",
    "\n",
    "### üöÄ Pr√≥ximos Pasos\n",
    "\n",
    "1. **Despliegue API (api/):**\n",
    "   - FastAPI endpoint para predicciones en tiempo real\n",
    "   - Validaci√≥n de inputs\n",
    "   - Documentaci√≥n Swagger\n",
    "\n",
    "2. **Interfaz Web (web/):**\n",
    "   - Streamlit dashboard interactivo\n",
    "   - Visualizaci√≥n de predicciones\n",
    "   - Upload de datos custom\n",
    "\n",
    "3. **Dockerizaci√≥n (docker/):**\n",
    "   - Dockerfile para API\n",
    "   - docker-compose.yml\n",
    "   - Despliegue containerizado\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ PROYECTO COMPLETADO CON √âXITO**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
