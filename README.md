# ğŸ›’ Walmart Sales Forecasting

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![scikit-learn](https://img.shields.io/badge/sklearn-1.3.2-orange.svg)
![XGBoost](https://img.shields.io/badge/XGBoost-2.0.2-red.svg)
![LightGBM](https://img.shields.io/badge/LightGBM-4.1.0-yellow.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28.2-red.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)

> **Sistema de Machine Learning para predicciÃ³n de ventas semanales en 45 tiendas Walmart usando algoritmos avanzados, con API REST y dashboard interactivo.**

---

## ğŸ‘¨â€ğŸ’» Autor

**Miguel Antonio BenÃ­tez GonzÃ¡lez**
- ğŸ“§ Email: mbenitezg01@gmail.com
- ğŸ’» GitHub: [miguelbenitez09](https://github.com/miguelbenitez09?tab=repositories)
- ğŸ’¼ LinkedIn: [Miguel Antonio BenÃ­tez GonzÃ¡lez](https://www.linkedin.com/in/miguel-antonio-ben%C3%ADtez-gonz%C3%A1lez-457816247/)

---

## ğŸ“‹ Tabla de Contenidos

1. [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
2. [Problema de Negocio](#-problema-de-negocio)
3. [Dataset](#-dataset)
4. [AnÃ¡lisis y TÃ©cnicas Aplicadas](#-anÃ¡lisis-y-tÃ©cnicas-aplicadas)
5. [Feature Engineering](#-feature-engineering)
6. [Modelos y Resultados](#-modelos-y-resultados)
7. [TecnologÃ­as Utilizadas](#ï¸-tecnologÃ­as-utilizadas)
8. [Estructura del Proyecto](#-estructura-del-proyecto)
9. [InstalaciÃ³n](#-instalaciÃ³n)
10. [Uso](#-uso)
11. [API Endpoints](#-api-endpoints)
12. [Mejoras Futuras](#-mejoras-futuras)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema completo de predicciÃ³n de ventas para Walmart, abarcando todo el pipeline de Data Science desde la exploraciÃ³n inicial hasta el despliegue en producciÃ³n.

### Objetivo Principal
Predecir las ventas semanales (`Weekly_Sales`) de diferentes departamentos en 45 tiendas Walmart, considerando factores como:
- DÃ­as festivos (Super Bowl, Thanksgiving, Christmas)
- Variables macroeconÃ³micas (CPI, desempleo, precio combustible)
- Promociones (MarkDown1-5)
- CaracterÃ­sticas de tiendas (tipo, tamaÃ±o)
- Factores temporales y estacionalidad

### Pipeline Completo
```
Datos Crudos â†’ EDA â†’ Feature Engineering â†’ Modelado ML â†’ API REST â†’ Dashboard Web
```

---

## ğŸ’¼ Problema de Negocio

### Contexto Empresarial
Walmart necesita optimizar su cadena de suministro y operaciones mediante la predicciÃ³n precisa de ventas semanales para:

1. **GestiÃ³n de Inventario** ğŸ“¦
   - Reducir sobrestock (costos de almacenamiento)
   - Evitar desabasto (pÃ©rdida de ventas)
   - Optimizar reposiciÃ³n de productos

2. **PlanificaciÃ³n de Recursos Humanos** ğŸ‘¥
   - Asignar personal segÃºn demanda esperada
   - Planificar turnos para dÃ­as festivos
   - Optimizar costos laborales

3. **Estrategias de Pricing y Promociones** ğŸ’°
   - Planificar descuentos (MarkDowns)
   - Maximizar ingresos en temporadas altas
   - Ajustar precios segÃºn demanda

### DesafÃ­os TÃ©cnicos

- **Datos Masivos**: 421,570 registros histÃ³ricos
- **MÃºltiples Series Temporales**: 45 tiendas Ã— 81 departamentos
- **Estacionalidad Compleja**: Patrones semanales, mensuales, anuales
- **Eventos Externos**: Impacto de festivos varÃ­a por tienda/departamento
- **MÃ©tricas Personalizadas**: WMAE con peso 5x en festivos

---

## ğŸ“Š Dataset

**Fuente**: [Walmart Recruiting - Store Sales Forecasting (Kaggle)](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting)

### InformaciÃ³n General
- **PerÃ­odo**: Febrero 2010 - Octubre 2012
- **Granularidad**: Semanal
- **Registros Entrenamiento**: 421,570
- **Tiendas**: 45
- **Departamentos**: 81

### Archivos

| Archivo | Registros | Columnas | DescripciÃ³n |
|---------|-----------|----------|-------------|
| `train.csv` | 421,570 | 5 | Ventas histÃ³ricas (target: Weekly_Sales) |
| `test.csv` | 115,064 | 4 | Datos para predicciÃ³n |
| `features.csv` | 8,190 | 12 | Variables semanales por tienda |
| `stores.csv` | 45 | 3 | InformaciÃ³n de tiendas (Type, Size) |

### Variables Principales

**train.csv**
- `Store`: ID de tienda (1-45)
- `Dept`: Departamento (1-99)
- `Date`: Fecha de la semana
- `Weekly_Sales`: Ventas semanales (target) - rango: $209 - $693,099
- `IsHoliday`: Indicador semana festiva

**features.csv**
- `Temperature`: Temperatura regional (Â°F)
- `Fuel_Price`: Precio combustible ($/galÃ³n)
- `MarkDown1-5`: Datos de promociones anonimizadas
- `CPI`: Ãndice Precios Consumidor
- `Unemployment`: Tasa desempleo (%)

**stores.csv**
- `Type`: Tipo de tienda (A, B, C)
- `Size`: TamaÃ±o en pies cuadrados

---

## ğŸ”¬ AnÃ¡lisis y TÃ©cnicas Aplicadas

### 1. AnÃ¡lisis Exploratorio de Datos (EDA)

**Notebook**: `notebooks/01_exploracion_dataset.ipynb`

#### AnÃ¡lisis Univariado
- **DistribuciÃ³n de ventas**: AsimetrÃ­a positiva (log-normal)
- **Outliers**: Detectados mediante Z-score (Â±3Ïƒ) e IQR
- **Missing values**: MarkDowns con ~50% NaN (promociones no aplicadas)

#### AnÃ¡lisis Temporal
```
Hallazgos Clave:
â”œâ”€â”€ Tendencia general alcista 2010-2012
â”œâ”€â”€ Estacionalidad fuerte: picos en Nov-Dic (Navidad)
â”œâ”€â”€ DÃ­as festivos: incremento promedio 40% en ventas
â””â”€â”€ Desplome enero: post-temporada navideÃ±a
```

#### AnÃ¡lisis por CategorÃ­as
- **Por Tipo de Tienda**:
  - Tipo A: Mayor volumen (55% ventas totales)
  - Tipo B: Volumen medio (30%)
  - Tipo C: Menor volumen (15%)
  
- **AnÃ¡lisis Pareto**: 20% de departamentos generan 60% de ventas

#### Correlaciones
```python
Correlaciones con Weekly_Sales:
â”œâ”€â”€ Size: 0.32 (tiendas grandes â†’ mÃ¡s ventas)
â”œâ”€â”€ Temperature: -0.15 (verano bajo, invierno alto)
â”œâ”€â”€ CPI: 0.18 (inflaciÃ³n correlaciona con ventas)
â””â”€â”€ Unemployment: -0.12 (desempleo reduce ventas)
```

#### TÃ©cnicas Utilizadas
- Visualizaciones: histogramas, boxplots, time series plots
- Matriz de correlaciÃ³n (Pearson)
- AnÃ¡lisis de estacionalidad
- DetecciÃ³n de outliers (Z-score, IQR)
- AnÃ¡lisis Pareto (regla 80/20)

---

### 2. Preprocesamiento de Datos

**Notebook**: `notebooks/02_preprocesamiento_dataset.ipynb`

#### Limpieza de Datos
```python
Pasos Aplicados:
â”œâ”€â”€ ImputaciÃ³n NaN en MarkDowns: 0 (sin promociÃ³n)
â”œâ”€â”€ ImputaciÃ³n NaN en CPI/Unemployment: forward fill temporal
â”œâ”€â”€ Merge de datasets: train + features + stores
â””â”€â”€ ValidaciÃ³n: 0 NaN finales, 0 duplicados
```

#### Transformaciones
- **Encoding CategÃ³rico**: Type de tienda (Aâ†’0, Bâ†’1, Câ†’2)
- **NormalizaciÃ³n**: Features numÃ©ricas (StandardScaler) post-split
- **Split Temporal**: Train 85% / ValidaciÃ³n 15% (respetando orden temporal)

#### Manejo de Outliers
```python
Estrategia:
â”œâ”€â”€ IdentificaciÃ³n: Z-score > 3
â”œâ”€â”€ AnÃ¡lisis: Â¿Genuinos o errores?
â”œâ”€â”€ DecisiÃ³n: Mantenidos (ventas legÃ­timas en festivos)
â””â”€â”€ WinsorizaciÃ³n: Limitados al percentil 99 para estabilidad
```

---

## âš™ï¸ Feature Engineering

**Notebook**: `notebooks/02_preprocesamiento_dataset.ipynb`

### Resumen de Features Creadas: 50+

#### 1ï¸âƒ£ Features Temporales (16 features)
Capturan estacionalidad y tendencias temporales.

```python
# Componentes BÃ¡sicos
- Year, Month, Week, Quarter
- DayOfWeek, DayOfYear

# Indicadores de PerÃ­odo
- IsMonthStart, IsMonthEnd
- IsQuarterStart, IsQuarterEnd
- WeekOfMonth

# Encoding CÃ­clico (evita discontinuidad 12â†’1)
- Month_sin = sin(2Ï€ Ã— Month / 12)
- Month_cos = cos(2Ï€ Ã— Month / 12)
- Week_sin = sin(2Ï€ Ã— Week / 52)
- Week_cos = cos(2Ï€ Ã— Week / 52)

# Tendencia
- Trend = dÃ­as desde inicio dataset / 7
```

**JustificaciÃ³n**: Patrones cÃ­clicos mensuales/semanales crÃ­ticos para retail. Encoding sin/cos evita que el modelo vea diciembre (12) lejos de enero (1).

---

#### 2ï¸âƒ£ Features de Festivos (8 features)
Los festivos tienen impacto 5x segÃºn mÃ©trica WMAE.

```python
# Identificadores de Festivos Principales
- IsSuperBowl: Super Bowl (semana 6 Feb)
- IsLaborDay: Labor Day (primer lunes Sept)
- IsThanksgiving: Thanksgiving (4Âº jueves Nov)
- IsChristmas: Christmas (semana 25 Dic)

# Proximidad a Festivos
- DaysToNextHoliday: dÃ­as hasta prÃ³ximo festivo
- DaysFromLastHoliday: dÃ­as desde Ãºltimo festivo
- IsPreHoliday: 7 dÃ­as antes de festivo
- IsPostHoliday: 7 dÃ­as despuÃ©s de festivo
```

**JustificaciÃ³n**: Los festivos generan picos de ventas. La proximidad captura comportamiento de compra anticipada y post-festiva.

---

#### 3ï¸âƒ£ Features de Lag (4 features)
Ventas pasadas son el mejor predictor de ventas futuras.

```python
# Ventas Semanas Previas
- Weekly_Sales_Lag1: semana anterior
- Weekly_Sales_Lag2: 2 semanas atrÃ¡s
- Weekly_Sales_Lag3: 3 semanas atrÃ¡s
- Weekly_Sales_Lag4: 4 semanas atrÃ¡s
```

**JustificaciÃ³n**: Capturan tendencias recientes y momentum. Lag4 captura comportamiento mensual.

---

#### 4ï¸âƒ£ Features Rolling Window (12 features)
EstadÃ­sticas mÃ³viles para suavizar ruido y capturar tendencias.

```python
# Ventanas de 4, 8, 12 semanas
Para cada ventana W:
- Weekly_Sales_RollingMean{W}: promedio mÃ³vil
- Weekly_Sales_RollingStd{W}: volatilidad
- Weekly_Sales_RollingMin{W}: mÃ­nimo perÃ­odo
- Weekly_Sales_RollingMax{W}: mÃ¡ximo perÃ­odo

Ejemplo: RollingMean4 = promedio Ãºltimas 4 semanas
```

**JustificaciÃ³n**: 
- RollingMean: Tendencia reciente sin ruido
- RollingStd: Volatilidad/estabilidad ventas
- RollingMin/Max: Rango de variaciÃ³n

---

#### 5ï¸âƒ£ Features Agregadas por Store-Dept (5 features)
CaracterÃ­sticas histÃ³ricas de cada combinaciÃ³n tienda-departamento.

```python
# EstadÃ­sticos HistÃ³ricos
- StoreDept_Mean: promedio histÃ³rico
- StoreDept_Std: desviaciÃ³n estÃ¡ndar
- StoreDept_Min: mÃ­nimo histÃ³rico
- StoreDept_Max: mÃ¡ximo histÃ³rico
- StoreDept_Median: mediana histÃ³rica
```

**JustificaciÃ³n**: Cada Store-Dept tiene comportamiento Ãºnico. Features capturan "nivel base" y variabilidad caracterÃ­stica.

---

#### 6ï¸âƒ£ Features de InteracciÃ³n (7 features)
Combinaciones de variables que capturan efectos conjuntos.

```python
# Interacciones Multiplicativas
- Temp_Month = Temperature Ã— Month
  (temperatura varÃ­a por mes â†’ interacciÃ³n captura estacionalidad clima)

- Size_Holiday = Size Ã— IsHoliday
  (tiendas grandes tienen mayor impacto festivo)

- Type_Holiday_Encoded = Type_Encoded Ã— IsHoliday
  (tipo de tienda modula efecto festivo)

- Store_Dept_Encoded = Store Ã— 100 + Dept
  (encoding Ãºnico para cada combinaciÃ³n)

# Agregaciones de Promociones
- Total_MarkDown = MarkDown1 + ... + MarkDown5
  (inversiÃ³n total en descuentos)

- Count_MarkDown = cantidad de MarkDowns activos
  (nÃºmero de promociones simultÃ¡neas)

# Ãndice EconÃ³mico
- Econ_Index = Unemployment Ã— CPI
  (captura condiciones macroeconÃ³micas generales)
```

**JustificaciÃ³n**: Efectos no son aditivos. Ej: temperatura alta en diciembre (calefacciÃ³n) vs julio (enfriamiento) tiene significado diferente.

---

### Total Features Finales: 66

```
13 originales + 50 creadas + 3 encoding = 66 features
```

### Impacto de Feature Engineering

| MÃ©trica | Sin FE | Con FE | Mejora |
|---------|--------|--------|--------|
| WMAE | $5,234 | $3,876 | â†“ 26% |
| MAE | $4,876 | $3,542 | â†“ 27% |
| RÂ² | 0.82 | 0.92 | â†‘ 12% |

---

## ğŸ¤– Modelos y Resultados

**Notebook**: `notebooks/03_modelado_dataset.ipynb`

### Algoritmos Evaluados

#### 1. Baseline (Linear Regression)
```python
ConfiguraciÃ³n:
â”œâ”€â”€ Algoritmo: RegresiÃ³n Lineal
â”œâ”€â”€ Features: 66 (estandarizadas)
â””â”€â”€ PropÃ³sito: Referencia de comparaciÃ³n

Resultados:
â”œâ”€â”€ WMAE: $5,234
â”œâ”€â”€ MAE: $4,876
â”œâ”€â”€ RMSE: $7,543
â”œâ”€â”€ RÂ²: 0.82
â””â”€â”€ Tiempo Entrenamiento: 0.5s
```

#### 2. Random Forest
```python
ConfiguraciÃ³n:
â”œâ”€â”€ n_estimators: 100 Ã¡rboles
â”œâ”€â”€ max_depth: 15
â”œâ”€â”€ min_samples_split: 10
â”œâ”€â”€ ParalelizaciÃ³n: n_jobs=-1
â””â”€â”€ Random State: 42

Resultados:
â”œâ”€â”€ WMAE: $4,321 (â†“17% vs baseline)
â”œâ”€â”€ MAE: $3,987
â”œâ”€â”€ RMSE: $6,125
â”œâ”€â”€ RÂ²: 0.89
â””â”€â”€ Tiempo: 12.3 min

Top 5 Features Importantes:
1. Weekly_Sales_Lag1: 0.28
2. StoreDept_Mean: 0.15
3. Size: 0.12
4. Weekly_Sales_RollingMean4: 0.09
5. IsHoliday: 0.07
```

#### 3. XGBoost ğŸ† (MEJOR MODELO)
```python
ConfiguraciÃ³n:
â”œâ”€â”€ n_estimators: 500
â”œâ”€â”€ max_depth: 7
â”œâ”€â”€ learning_rate: 0.05
â”œâ”€â”€ subsample: 0.8
â”œâ”€â”€ colsample_bytree: 0.8
â”œâ”€â”€ objective: reg:squarederror
â””â”€â”€ early_stopping: 50 rounds

Resultados:
â”œâ”€â”€ WMAE: $3,876 (â†“26% vs baseline) â­
â”œâ”€â”€ MAE: $3,542
â”œâ”€â”€ RMSE: $5,678
â”œâ”€â”€ RÂ²: 0.92
â””â”€â”€ Tiempo: 8.7 min

Top 5 Features Importantes:
1. Weekly_Sales_Lag1: 0.32
2. StoreDept_Mean: 0.18
3. Weekly_Sales_RollingMean4: 0.11
4. Size: 0.09
5. Trend: 0.06
```

#### 4. LightGBM
```python
ConfiguraciÃ³n:
â”œâ”€â”€ n_estimators: 500
â”œâ”€â”€ max_depth: 8
â”œâ”€â”€ learning_rate: 0.05
â”œâ”€â”€ num_leaves: 31
â”œâ”€â”€ objective: regression
â””â”€â”€ metric: mae

Resultados:
â”œâ”€â”€ WMAE: $3,942
â”œâ”€â”€ MAE: $3,601
â”œâ”€â”€ RMSE: $5,734
â”œâ”€â”€ RÂ²: 0.91
â””â”€â”€ Tiempo: 3.2 min (mÃ¡s rÃ¡pido)
```

---

### ComparaciÃ³n de Modelos

| Modelo | WMAE | MAE | RMSE | RÂ² | Tiempo | SelecciÃ³n |
|--------|------|-----|------|-----|--------|-----------|
| Baseline | $5,234 | $4,876 | $7,543 | 0.82 | 0.5s | âŒ |
| Random Forest | $4,321 | $3,987 | $6,125 | 0.89 | 12.3m | âŒ |
| **XGBoost** | **$3,876** | **$3,542** | **$5,678** | **0.92** | 8.7m | âœ… |
| LightGBM | $3,942 | $3,601 | $5,734 | 0.91 | 3.2m | âŒ |

**Modelo Seleccionado**: XGBoost por mejor WMAE (mÃ©trica objetivo del proyecto).

---

### TÃ©cnicas de ValidaciÃ³n

1. **Split Temporal**: 85% train / 15% validation (respeta serie temporal)
2. **No Cross-Validation**: ValidaciÃ³n temporal mÃ¡s apropiada que K-Fold para series temporales
3. **Early Stopping**: Previene overfitting en gradient boosting
4. **Feature Importance**: AnÃ¡lisis de features mÃ¡s relevantes

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Ciencia de Datos
| TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|------------|---------|-----------|
| Python | 3.10+ | Lenguaje principal |
| pandas | 2.1.3 | ManipulaciÃ³n de datos |
| numpy | 1.26.2 | CÃ¡lculos numÃ©ricos |
| scikit-learn | 1.3.2 | Preprocesamiento, Random Forest, mÃ©tricas |
| XGBoost | 2.0.2 | Gradient Boosting (modelo final) |
| LightGBM | 4.1.0 | Gradient Boosting alternativo |
| joblib | 1.3.2 | SerializaciÃ³n de modelos |

### VisualizaciÃ³n
| TecnologÃ­a | PropÃ³sito |
|------------|-----------|
| matplotlib | GrÃ¡ficos estÃ¡ticos |
| seaborn | Visualizaciones estadÃ­sticas |
| plotly | GrÃ¡ficos interactivos (dashboard) |

### Deployment
| TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|------------|---------|-----------|
| FastAPI | 0.104.1 | API REST para predicciones |
| Streamlit | 1.28.2 | Dashboard web interactivo |
| uvicorn | 0.24.0 | Servidor ASGI para FastAPI |
| pydantic | 2.5.0 | ValidaciÃ³n de datos API |
| Docker | latest | ContainerizaciÃ³n |
| Docker Compose | latest | OrquestaciÃ³n multi-contenedor |

---

## ğŸ“ Estructura del Proyecto

```
walmart_sales_forecasting/
â”‚
â”œâ”€â”€ data/                           # Datos del proyecto
â”‚   â”œâ”€â”€ 01_raw/                     # Datos originales (421K registros)
â”‚   â”‚   â”œâ”€â”€ train.csv               # Ventas histÃ³ricas
â”‚   â”‚   â”œâ”€â”€ test.csv                # Datos para predicciÃ³n
â”‚   â”‚   â”œâ”€â”€ features.csv            # Variables semanales
â”‚   â”‚   â””â”€â”€ stores.csv              # Info tiendas
â”‚   â”‚
â”‚   â””â”€â”€ 02_processed/               # Datos procesados
â”‚       â”œâ”€â”€ train_processed.csv     # Train con 66 features
â”‚       â”œâ”€â”€ val_processed.csv       # ValidaciÃ³n
â”‚       â””â”€â”€ test_processed.csv      # Test
â”‚
â”œâ”€â”€ notebooks/                      # AnÃ¡lisis Jupyter
â”‚   â”œâ”€â”€ 01_exploracion_dataset.ipynb       # EDA completo
â”‚   â”œâ”€â”€ 02_preprocesamiento_dataset.ipynb  # Feature Engineering
â”‚   â””â”€â”€ 03_modelado_dataset.ipynb          # Entrenamiento modelos
â”‚
â”œâ”€â”€ models/                         # Modelos ML serializados
â”‚   â”œâ”€â”€ best_model.pkl              # XGBoost (272 MB)
â”‚   â”œâ”€â”€ best_model_compressed.pkl   # Comprimido (93 MB)
â”‚   â””â”€â”€ model_info.pkl              # Metadata del modelo
â”‚
â”œâ”€â”€ api/                            # API REST
â”‚   â”œâ”€â”€ main.py                     # FastAPI app
â”‚   â””â”€â”€ requirements.txt            # Dependencias API
â”‚
â”œâ”€â”€ web/                            # Dashboard Web
â”‚   â”œâ”€â”€ app.py                      # Streamlit app
â”‚   â”œâ”€â”€ requirements.txt            # Dependencias web
â”‚   â””â”€â”€ README.md                   # DocumentaciÃ³n web
â”‚
â”œâ”€â”€ docker/                         # ContainerizaciÃ³n
â”‚   â”œâ”€â”€ Dockerfile                  # Imagen Docker
â”‚   â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n
â”‚   â””â”€â”€ README.md                   # GuÃ­a Docker
â”‚
â”œâ”€â”€ .gitignore                      # Archivos ignorados
â””â”€â”€ README.md                       # Este archivo
```

---

## ğŸš€ InstalaciÃ³n

### Requisitos Previos
- Python 3.10 o superior
- Docker y Docker Compose (para deployment containerizado)
- Git

### OpciÃ³n 1: InstalaciÃ³n Local

#### 1. Clonar Repositorio
```bash
git clone https://github.com/miguelbenitez09/walmart-sales-forecasting.git
cd walmart-sales-forecasting
```

#### 2. Crear Entorno Virtual
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

#### 3. Instalar Dependencias

**Para Notebooks**:
```bash
pip install pandas numpy scikit-learn xgboost lightgbm matplotlib seaborn plotly jupyter
```

**Para API**:
```bash
cd api
pip install -r requirements.txt
```

**Para Dashboard**:
```bash
cd web
pip install -r requirements.txt
```

#### 4. Descargar Datos
Los datos estÃ¡n incluidos en el repositorio en `data/01_raw/`. Si necesitas descargarlos nuevamente:
```bash
# Descargar desde Kaggle
# Requiere kaggle API configurada
kaggle competitions download -c walmart-recruiting-store-sales-forecasting
```

---

### OpciÃ³n 2: Deployment con Docker (Recomendado) ğŸ³

#### 1. Clonar Repositorio
```bash
git clone https://github.com/miguelbenitez09/walmart-sales-forecasting.git
cd walmart-sales-forecasting
```

#### 2. Construir y Ejecutar Contenedores
```bash
cd docker
docker-compose up --build -d
```

Esto levantarÃ¡:
- **API REST**: http://localhost:8006
- **Dashboard Web**: http://localhost:8506

#### 3. Verificar Contenedores
```bash
docker ps
# DeberÃ­as ver walmart_api y walmart_web corriendo
```

#### 4. Ver Logs
```bash
docker logs walmart_api
docker logs walmart_web
```

#### 5. Detener Servicios
```bash
docker-compose down
```

---

## ğŸ’» Uso

### 1. Ejecutar Notebooks de AnÃ¡lisis

```bash
# Activar entorno virtual
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Iniciar Jupyter
jupyter notebook

# Abrir notebooks en orden:
# 1. notebooks/01_exploracion_dataset.ipynb
# 2. notebooks/02_preprocesamiento_dataset.ipynb
# 3. notebooks/03_modelado_dataset.ipynb
```

---

### 2. Usar API REST

#### Iniciar API Localmente
```bash
cd api
uvicorn main:app --host 0.0.0.0 --port 8006 --reload
```

#### DocumentaciÃ³n AutomÃ¡tica
- Swagger UI: http://localhost:8006/docs
- ReDoc: http://localhost:8006/redoc

#### Ejemplo de Solicitud (Python)
```python
import requests

url = "http://localhost:8006/predict"
data = {
    "Store": 1,
    "Dept": 1,
    "Date": "2012-11-02",
    "Temperature": 42.31,
    "Fuel_Price": 2.572,
    "MarkDown1": 0.0,
    "MarkDown2": 0.0,
    "MarkDown3": 0.0,
    "MarkDown4": 0.0,
    "MarkDown5": 0.0,
    "CPI": 211.096358,
    "Unemployment": 8.106,
    "IsHoliday": 0,
    "Type": "A",
    "Size": 151315
}

response = requests.post(url, json=data)
print(response.json())
# Output: {"prediction": 15359.31, "store": 1, "dept": 1, "is_holiday": false}
```

#### Ejemplo de Solicitud (cURL)
```bash
curl -X POST "http://localhost:8006/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "Store": 1,
       "Dept": 1,
       "Date": "2012-11-02",
       "Temperature": 42.31,
       "Fuel_Price": 2.572,
       "MarkDown1": 0.0,
       "MarkDown2": 0.0,
       "MarkDown3": 0.0,
       "MarkDown4": 0.0,
       "MarkDown5": 0.0,
       "CPI": 211.096358,
       "Unemployment": 8.106,
       "IsHoliday": 0,
       "Type": "A",
       "Size": 151315
     }'
```

---

### 3. Usar Dashboard Web

#### Iniciar Dashboard Localmente
```bash
cd web
streamlit run app.py --server.port 8506
```

Abrir en navegador: http://localhost:8506

#### Funcionalidades del Dashboard
1. **PredicciÃ³n Individual**: Ingresa parÃ¡metros manualmente
2. **PredicciÃ³n por Tienda**: Selecciona tienda y fecha
3. **PredicciÃ³n Masiva**: Sube archivo CSV con mÃºltiples predicciones
4. **Visualizaciones**: GrÃ¡ficos de tendencias y distribuciones
5. **InformaciÃ³n del Modelo**: MÃ©tricas y features importantes

---

## ğŸŒ API Endpoints

### Base URL
```
http://localhost:8006
```

### Endpoints Disponibles

#### 1. Health Check
```http
GET /health
```

**Respuesta**:
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_type": "XGBoost"
}
```

---

#### 2. PredicciÃ³n Individual
```http
POST /predict
```

**Request Body**:
```json
{
  "Store": 1,
  "Dept": 1,
  "Date": "2012-11-02",
  "Temperature": 42.31,
  "Fuel_Price": 2.572,
  "MarkDown1": 0.0,
  "MarkDown2": 0.0,
  "MarkDown3": 0.0,
  "MarkDown4": 0.0,
  "MarkDown5": 0.0,
  "CPI": 211.096358,
  "Unemployment": 8.106,
  "IsHoliday": 0,
  "Type": "A",
  "Size": 151315
}
```

**Respuesta**:
```json
{
  "prediction": 15359.31,
  "store": 1,
  "dept": 1,
  "is_holiday": false
}
```

---

#### 3. PredicciÃ³n Batch
```http
POST /predict/batch
```

**Request Body**:
```json
{
  "predictions": [
    {
      "Store": 1,
      "Dept": 1,
      "Date": "2012-11-02",
      ...
    },
    {
      "Store": 2,
      "Dept": 3,
      "Date": "2012-11-09",
      ...
    }
  ]
}
```

**Respuesta**:
```json
{
  "predictions": [
    {"prediction": 15359.31, "store": 1, "dept": 1, ...},
    {"prediction": 23104.67, "store": 2, "dept": 3, ...}
  ],
  "count": 2
}
```

---

## ğŸ”® Mejoras Futuras

### Modelado
- [ ] **Modelos de Series Temporales**: Prophet, ARIMA, SARIMA
- [ ] **Deep Learning**: LSTM, GRU para capturar dependencias temporales largas
- [ ] **Ensemble**: CombinaciÃ³n ponderada de XGBoost + LightGBM + LSTM
- [ ] **Hyperparameter Tuning**: Grid Search / Bayesian Optimization
- [ ] **Features Adicionales**: Clima histÃ³rico, competencia, eventos locales

### IngenierÃ­a
- [ ] **Pipeline Automatizado**: Airflow para ETL y reentrenamiento
- [ ] **Monitoreo**: MLflow para tracking de experimentos
- [ ] **CI/CD**: GitHub Actions para deployment automÃ¡tico
- [ ] **Escalabilidad**: Kubernetes para manejo de alta carga
- [ ] **Base de Datos**: PostgreSQL para almacenar predicciones

### Producto
- [ ] **Alertas**: Notificaciones de predicciones anÃ³malas
- [ ] **Explicabilidad**: SHAP values para interpretar predicciones
- [ ] **A/B Testing**: ComparaciÃ³n de modelos en producciÃ³n
- [ ] **App MÃ³vil**: Flutter para gestores de tienda
- [ ] **IntegraciÃ³n ERP**: ConexiÃ³n con sistemas Walmart

---

## ğŸ“ Contacto y Soporte

Si tienes preguntas o sugerencias sobre este proyecto:

- ğŸ“§ Email: mbenitezg01@gmail.com
- ğŸ’¼ LinkedIn: [Miguel Antonio BenÃ­tez GonzÃ¡lez](https://www.linkedin.com/in/miguel-antonio-ben%C3%ADtez-gonz%C3%A1lez-457816247/)
- ğŸ’» GitHub: [miguelbenitez09](https://github.com/miguelbenitez09?tab=repositories)

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ™ Agradecimientos

- **Kaggle**: Por proporcionar el dataset
- **Walmart**: Por el caso de estudio real
- **Comunidad Open Source**: Scikit-learn, XGBoost, FastAPI, Streamlit

---

**Desarrollado con â¤ï¸ por Miguel Antonio BenÃ­tez GonzÃ¡lez**

*Ãšltima actualizaciÃ³n: Diciembre 2025*
